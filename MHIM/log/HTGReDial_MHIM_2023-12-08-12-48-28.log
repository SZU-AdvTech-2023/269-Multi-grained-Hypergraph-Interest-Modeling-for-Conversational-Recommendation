2023-12-08 12:48:28.682 | INFO     | crslab.config.config:__init__:87 - [Dataset: HTGReDial tokenized in pkuseg]
2023-12-08 12:48:28.683 | INFO     | crslab.config.config:__init__:89 - [Model: MHIM]
2023-12-08 12:48:28.683 | INFO     | crslab.config.config:__init__:96 - [Config]
{
    "dataset": "HTGReDial",
    "tokenize": "pkuseg",
    "related_truncate": 1024,
    "context_truncate": 256,
    "response_truncate": 30,
    "scale": 1,
    "model": "MHIM",
    "token_emb_dim": 300,
    "kg_emb_dim": 128,
    "num_bases": 8,
    "n_heads": 2,
    "n_layers": 2,
    "ffn_size": 300,
    "dropout": 0.1,
    "attention_dropout": 0.0,
    "relu_dropout": 0.1,
    "learn_positional_embeddings": false,
    "embeddings_scale": true,
    "reduction": false,
    "n_positions": 1024,
    "user_proj_dim": 512,
    "mha_n_heads": 4,
    "pooling": "Attn",
    "extension_strategy": "Adaptive",
    "rec": {
        "epoch": 100,
        "batch_size": 64,
        "early_stop": true,
        "stop_mode": "min",
        "impatience": 2,
        "optimizer": {
            "name": "Adam",
            "lr": 0.001
        }
    },
    "conv": {
        "epoch": 5,
        "batch_size": 128,
        "impatience": 1,
        "optimizer": {
            "name": "Adam",
            "lr": 0.001
        },
        "lr_scheduler": {
            "name": "ReduceLROnPlateau",
            "patience": 3,
            "factor": 0.5
        },
        "gradient_clip": 0.1
    },
    "pretrain": true,
    "pretrain_epoch": 10,
    "gpu": [
        0
    ],
    "model_name": "MHIM"
}
2023-12-08 12:48:45.126 | INFO     | crslab.data.dataset.base:__init__:49 - [Finish data load]
2023-12-08 13:02:54.388 | INFO     | crslab.data.dataset.base:__init__:57 - [Finish data preprocess]
2023-12-08 13:02:56.481 | INFO     | crslab.model.crs.mhim.mhim:build_model:152 - [Load Pretrain Weights from pretrain/HTGReDial/10-epoch.pth]
